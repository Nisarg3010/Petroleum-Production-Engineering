{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook - Chapter06_Reservoir Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importing basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import random\n",
    "import xlrd\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# visualization/plotting libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.style\n",
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt\n",
    "# setting to default parameters\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "# formatting for decimal places\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# matplotlib settings\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.style.use('seaborn-white')\n",
    "mpl.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "mpl.rcParams[\"axes.grid\"] = False\n",
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\ayush\\Desktop\\ML Book\\Pandey_Ch06_Reservoir_Engineering_Code\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed for model reproducibility\n",
    "seed_value = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the destination for the data folder\n",
    "path = os.path.join(os.getcwd(), \"../data\")\n",
    "norm_path = os.path.normpath(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to scrape NDIC data\n",
    "# https://www.dmr.nd.gov/oilgas/\n",
    "# data from May 2015 to December 2018 will be used as a training dataset\n",
    "# data from 2019 will be used as a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to scrape data from NDIC\n",
    "def scrape_ndic(months_list):\n",
    "    '''function to scrape NDIC data'''\n",
    "    # link to website with production data\n",
    "    website = \"https://www.dmr.nd.gov/oilgas/mpr/\"\n",
    "    df = pd.DataFrame()\n",
    "    # loop through all of the dates in the list\n",
    "    for period in months_list:\n",
    "        url = website + period + \".xlsx\"\n",
    "        req = requests.get(url)\n",
    "        book = xlrd.open_workbook(file_contents=req.content)\n",
    "        sheet = book.sheet_by_index(0)\n",
    "        for i in range(1, sheet.nrows):\n",
    "            temp_value = sheet.cell_value(i, 0)\n",
    "            year, month, day, hour, minute, second = xlrd.xldate_as_tuple(temp_value, book.datemode)\n",
    "            sheet._cell_values[i][0] = datetime(year, month, 1).strftime(\"%m/%Y\")\n",
    "        new_file = (path + '\\\\'+ period + \".csv\")\n",
    "        csv_file = open(new_file, \"w\", newline=\"\")\n",
    "        writer = csv.writer(csv_file)\n",
    "        # iteration through each row for data pull\n",
    "        for rownum in range(sheet.nrows):\n",
    "            writer.writerow(sheet.row_values(rownum))\n",
    "        csv_file.close()\n",
    "        df = pd.read_csv(new_file)\n",
    "        df = df.append(df)\n",
    "    # dataframe with entire monthly production\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = [\"2015_05\",\"2015_06\",\"2015_07\",\"2015_08\",\"2015_09\",\"2015_10\",\"2015_11\",\"2015_12\",\n",
    "    \"2016_01\",\"2016_02\",\"2016_03\",\"2016_04\",\"2016_05\",\"2016_06\",\"2016_07\",\"2016_08\",\"2016_09\",\"2016_10\",\"2016_11\",\"2016_12\",\n",
    "    \"2017_01\",\"2017_02\",\"2017_03\",\"2017_04\",\"2017_05\",\"2017_06\",\"2017_07\",\"2017_08\",\"2017_09\",\"2017_10\",\"2017_11\",\"2017_12\",\n",
    "    \"2018_01\",\"2018_02\",\"2018_03\",\"2018_04\",\"2018_05\",\"2018_06\",\"2018_07\",\"2018_08\",\"2018_09\",\"2018_10\",\"2018_11\",\"2018_12\"]\n",
    "train_prod_data = scrape_ndic(train_list)\n",
    "train_prod_data[\"ReportDate\"] = pd.to_datetime(train_prod_data[\"ReportDate\"])\n",
    "#train_prod_data.to_csv(\"train_prod.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [\"2019_01\",\"2019_02\",\"2019_03\",\"2019_04\",\"2019_05\",\"2019_06\",\"2019_07\",\"2019_08\",\"2019_09\",\"2019_10\",\"2019_11\",\"2019_12\"]\n",
    "test_prod_data = scrape_ndic(test_list)\n",
    "test_prod_data[\"ReportDate\"] = pd.to_datetime(test_prod_data[\"ReportDate\"])\n",
    "#test_prod_data.to_csv(\"test_prod.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARPS Decline Curve Analysis\n",
    "\n",
    "def pre_process(df, column):\n",
    "    df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "    df.info()\n",
    "    print(df.columns)\n",
    "    # descriptive statistics\n",
    "    df.describe().T\n",
    "    df.head(15)\n",
    "    df.nunique()    \n",
    "    df.dtypes\n",
    "    df.shape\n",
    "    # filtering\n",
    "    df.dropna(inplace=True)\n",
    "    # drop rows where oil rate is 0\n",
    "    df = df[(df[column].notnull()) & (df[column] > 0)]\n",
    "    return df\n",
    "\n",
    "def plot_production_rate(df):\n",
    "    '''Plot decline curve using production rates'''\n",
    "    sns.lineplot(x = df['ReportDate'], y = df['oil_rate'], markers=True, dashes=False, \n",
    "                 label=\"Oil Production\",color='blue', linewidth=1.5)\n",
    "    plt.title('Decline Curve', fontweight='bold', fontsize = 20)\n",
    "    plt.xlabel('Time', fontweight='bold', fontsize = 15)\n",
    "    plt.ylabel('Oil Production Rate (bbl/d)', fontweight='bold', fontsize = 15)\n",
    "    plt.show()\n",
    "\n",
    "def decline_curve(curve_type, q_i):\n",
    "    if curve_type == \"exponential\":\n",
    "\n",
    "        def exponential_decline(T, d):\n",
    "            return q_i * np.exp(-d * T)\n",
    "        return exponential_decline\n",
    "\n",
    "    elif curve_type == \"hyperbolic\":\n",
    "\n",
    "        def hyperbolic_decline(T, d_i, b):\n",
    "            return q_i / np.power((1 + b * d_i * T), 1.0 / b)\n",
    "        return hyperbolic_decline\n",
    "\n",
    "    elif curve_type == \"harmonic\":\n",
    "\n",
    "        def parabolic_decline(T, d_i):\n",
    "            return q_i / (1 + d_i * T)\n",
    "        return parabolic_decline\n",
    "\n",
    "    else:\n",
    "        raise \"Unknown Decline Curve!\"\n",
    "\n",
    "\n",
    "def L2_norm(Q, Q_obs):\n",
    "    return np.sum(np.power(np.subtract(Q, Q_obs), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading train and test data\n",
    "\n",
    "train_prod = pd.read_csv('train_prod.csv')\n",
    "test_prod = pd.read_csv(\"test_prod.csv\")\n",
    "\n",
    "# Basic Processing and data exploration\n",
    "train_prod = pre_process(train_prod, 'Oil')\n",
    "test_prod = pre_process(test_prod, 'Oil')\n",
    "\n",
    "# convert time to datetime and set as dataframe index\n",
    "train_prod[\"ReportDate\"] = pd.to_datetime(train_prod[\"ReportDate\"])\n",
    "test_prod[\"ReportDate\"] = pd.to_datetime(test_prod[\"ReportDate\"])\n",
    "\n",
    "#bakken_data.set_index(\"ReportDate\", inplace=True)\n",
    "train_prod[\"First_Prod_Date\"] = train_prod.groupby(\"API_WELLNO\")[\"ReportDate\"].transform('min')\n",
    "train_prod[\"Days_Online\"] = (train_prod[\"ReportDate\"] - train_prod[\"First_Prod_Date\"]).dt.days \n",
    "\n",
    "# find the top 10 wells with highest production (sum)\n",
    "grouped_data = train_prod.groupby(['API_WELLNO']).sum()\n",
    "grouped_data = grouped_data.sort_values(by=['Oil'])\n",
    "grouped_data = grouped_data.nlargest(10, 'Oil').reset_index()\n",
    "\n",
    "example_wells = grouped_data['API_WELLNO'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (example_wells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "demo_well = [33053059210000, 33025021780000]\n",
    "\n",
    "print('API:', demo_well)\n",
    "df_temp = train_prod[train_prod['API_WELLNO'] == demo_well[1]]\n",
    "df_temp[\"oil_rate\"] = df_temp[\"Oil\"] / df_temp[\"Days\"]\n",
    "df_temp['date_delta'] = (df_temp['ReportDate'] - df_temp['ReportDate'].min())/np.timedelta64(1,'D')\n",
    "plot_production_rate(df_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_temp[['date_delta', 'oil_rate']]\n",
    "data = df_temp.to_numpy()\n",
    "# T is number of days of production - cumulative\n",
    "# q is production rate\n",
    "T_train, q = data.T\n",
    "print(T_train)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption - determine qi from max value of first 3 months of production\n",
    "df_initial_period = df_temp.head(3)\n",
    "qi = df_initial_period['oil_rate'].max()\n",
    "\n",
    "exp_decline = decline_curve(\"exponential\", qi)\n",
    "hyp_decline = decline_curve(\"hyperbolic\", qi)\n",
    "har_decline = decline_curve(\"harmonic\", qi)\n",
    "\n",
    "popt_exp, pcov_exp = curve_fit(exp_decline, T_train, q, method=\"trf\")\n",
    "popt_hyp, pcov_hyp = curve_fit(hyp_decline, T_train, q, method=\"trf\")\n",
    "popt_har, pcov_har = curve_fit(har_decline, T_train, q, method=\"trf\")\n",
    "\n",
    "print(\"L2 Norm of exponential decline: \", L2_norm(exp_decline(T_train, popt_exp[0]), q))\n",
    "print(\"L2 Norm of hyperbolic decline decline: \",L2_norm(hyp_decline(T_train, popt_hyp[0], popt_hyp[1]), q))\n",
    "print(\"L2 Norm of harmonic decline decline: \", L2_norm(har_decline(T_train, popt_har[0]), q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "plt.scatter(T_train, q, color=\"black\", marker=\"x\", alpha=1)\n",
    "pred_exp = exp_decline(T_train, popt_exp[0])\n",
    "pred_hyp = hyp_decline(T_train, popt_hyp[0], popt_hyp[1])\n",
    "pred_har = har_decline(T_train, popt_har[0])\n",
    "plt.plot(T_train, pred_exp, color=\"red\", label=\"Exponential\", linewidth = 4)\n",
    "plt.plot(T_train, pred_hyp, color=\"green\", label=\"Hyperbolic\", linestyle=\"--\", linewidth = 4)\n",
    "plt.plot(T_train, pred_har, color=\"blue\", label=\"Harmonic\", linestyle = ':', linewidth = 4)\n",
    "plt.title('History Match', fontweight='bold', fontsize = 20)\n",
    "plt.xlabel('Time', fontweight='bold', fontsize = 15)\n",
    "plt.ylabel('Oil Production Rate (bbl/d)', fontweight='bold', fontsize = 15)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast\n",
    "max_time_forecast = 5000\n",
    "T_pred = np.linspace(min(T_train), max_time_forecast)\n",
    "plt.scatter(T_train, q, color=\"black\", marker=\"x\", alpha=1)\n",
    "pred_exp = exp_decline(T_pred, popt_exp[0])\n",
    "pred_hyp = hyp_decline(T_pred, popt_hyp[0], popt_hyp[1])\n",
    "pred_har = har_decline(T_pred, popt_har[0])\n",
    "plt.plot(T_pred, pred_exp, color=\"red\", label=\"Exponential\", linewidth = 4)\n",
    "plt.plot(T_pred, pred_hyp, color=\"green\", label=\"Hyperbolic\", linestyle=\"--\", linewidth = 4)\n",
    "plt.plot(T_pred, pred_har, color=\"blue\", label=\"Harmonic\", linestyle = ':', linewidth = 4)\n",
    "plt.title('Forecast', fontweight='bold', fontsize = 20)\n",
    "plt.xlabel('Time', fontweight='bold', fontsize = 15)\n",
    "plt.ylabel('Oil Production Rate (bbl/d)', fontweight='bold', fontsize = 15)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation procedure\n",
    "\n",
    "print('API:', demo_well[1])\n",
    "df_temp_test = test_prod[test_prod['API_WELLNO'] == demo_well[1]]\n",
    "df_temp_test[\"oil_rate\"] = df_temp_test[\"Oil\"] / df_temp_test[\"Days\"]\n",
    "df_temp_test['date_delta'] = (df_temp_test['ReportDate'] - df_temp_test['ReportDate'].min())  / np.timedelta64(1,'D')\n",
    "print(df_temp_test)\n",
    "df_temp_test = df_temp_test[['date_delta', 'oil_rate']]\n",
    "data_test = df_temp_test.to_numpy()\n",
    "# T is number of days of production - cumulative\n",
    "# q is production rate\n",
    "T_test, q_test = data_test.T\n",
    "\n",
    "#T_test = np.concatenate(T_train, T)\n",
    "print(T_test)\n",
    "print(q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = pd.date_range(start='6/1/2015', periods= 54, freq='MS')\n",
    "time\n",
    "T_Test2 = T_train[-1] + T_test\n",
    "len(T_train)\n",
    "pred_hyp =  hyp_decline(T_train, popt_hyp[0], popt_hyp[1])\n",
    "pred_hyp2 = hyp_decline(T_Test2, popt_hyp[0], popt_hyp[1])\n",
    "print(pred_hyp)\n",
    "print(pred_hyp2)\n",
    "# forecast\n",
    "q_orig = np.append(q, q_test)\n",
    "forecast = np.concatenate([pred_hyp, pred_hyp2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperbolic forecast - plot\n",
    "plt.plot(time, q_orig, color=\"black\", alpha = 0.8, label='Actual Data', linewidth = 4)\n",
    "plt.plot(time, forecast, color=\"green\", label=\"Hyperbolic Trend\", linewidth = 4, linestyle=\"--\")\n",
    "plt.title('Production Forecast', fontweight='bold', fontsize = 20)\n",
    "plt.xlabel('Time', fontweight='bold', fontsize = 15)\n",
    "plt.ylabel('Oil Production Rate (bbl/d)', fontweight='bold', fontsize = 15)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "rmse = sqrt(mean_squared_error(q_orig, forecast))\n",
    "print(\"RMSE - Hyperbolic Method:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA MODEL BASED DCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_production_series(series):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(series, color = 'blue')\n",
    "    plt.title(\"Oil Production Decline\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Production Rate (bbls/d)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data \n",
    "train_prod = pd.read_csv('train_prod.csv')\n",
    "test_prod = pd.read_csv(\"test_prod.csv\")\n",
    "print('Training Data:\\n', train_prod.head(10))\n",
    "print('\\n')\n",
    "print('Test Data:\\n', train_prod.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing on train data\n",
    "# well selection for demo - time series\n",
    "train_prod = train_prod[train_prod[\"API_WELLNO\"] == 33025021780000.0]\n",
    "train_prod.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "train_prod[\"ReportDate\"] = pd.to_datetime(train_prod[\"ReportDate\"])\n",
    "train_prod.set_index(\"ReportDate\", inplace=True)\n",
    "train_prod.nunique()\n",
    "\n",
    "# converting data from dataframe to series - oil production\n",
    "timeseries_train= train_prod[\"Oil\"]\n",
    "timeseries_train.head()\n",
    "plot_production_series(timeseries_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing on test data\n",
    "# well selection for demo - time series\n",
    "test_prod = test_prod[test_prod[\"API_WELLNO\"] == 33025021780000.0]\n",
    "test_prod.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "test_prod[\"ReportDate\"] = pd.to_datetime(test_prod[\"ReportDate\"])\n",
    "test_prod.set_index(\"ReportDate\", inplace=True)\n",
    "test_prod.nunique()\n",
    "\n",
    "# time series is production volumes and not flow rates\n",
    "timeseries_test = test_prod[\"Oil\"]\n",
    "timeseries_test.head()\n",
    "plot_production_series(timeseries_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADF - Augmented Dickey-Fuller unit root test - to test stationarity\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "print(\"p-value:\", adfuller(timeseries_train.dropna())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Dickey-Fuller test:\n",
    "def dickey_ful_test(series):\n",
    "    print(\"Results of Dickey-Fuller Test:\")\n",
    "    df_test = adfuller(series, autolag=\"AIC\")\n",
    "    df_output = pd.Series(df_test[0:4],index=[\"Test Statistic\",\"p-value\",\"#Lags Used\",\"Number of Observations Used\"])\n",
    "    for key, value in df_test[4].items():\n",
    "        df_output[\"Critical Value (%s)\" % key] = value\n",
    "    print(df_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationary_test_plot(metric, data_series, method):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    orig = plt.plot(data_series, label=\"Original\", color = 'blue')\n",
    "    metric = plt.plot(metric, label= method, color ='red')\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(method)\n",
    "    plt.xlabel('Time (yyyy-mm)')\n",
    "    plt.ylabel('Oil Production (bbls)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stationary_test(data_series, method):\n",
    "    rolling_mean = data_series.rolling(10).mean()\n",
    "    stationary_test_plot(rolling_mean, data_series, method)\n",
    "    dickey_ful_test(data_series)\n",
    "\n",
    "# test if the time series data is stationary or not\n",
    "stationary_test(timeseries_train, \"Rolling Mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(y_axis, x_label, y_label, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_axis, label = y_label, color = 'blue')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y axis transformation - log(data)\n",
    "ts_log = np.log(timeseries_train)\n",
    "plot_time_series(ts_log, \"Time (yyyy-mm)\", \"log (Oil Production (bbls))\", \"Plot with Log transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling mean estimation and plot\n",
    "rolling_mean_log = ts_log.rolling(10).mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "orig = plt.plot(ts_log, label=\"Original\", color = 'blue')\n",
    "mean = plt.plot(rolling_mean_log, label=\"Rolling Mean\", color ='red')\n",
    "plt.title(\"Rolling Mean - With Log Transformation\")\n",
    "plt.xlabel('Time (yyyy-mm)')\n",
    "plt.ylabel('log(Oil Production (bbls))')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of difference between log(data) and moving average\n",
    "diff_log_rolmean = ts_log - rolling_mean_log\n",
    "diff_log_rolmean.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_test(diff_log_rolmean, \"Diff - Log and Rolling Mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponential weighted calculations\n",
    "weighted_avg_exp = ts_log.ewm(halflife=2).mean()\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "orig = plt.plot(ts_log, label=\"Original\", color = 'blue')\n",
    "mean = plt.plot(weighted_avg_exp, label=\"Exponential Weighted Mean\", color ='red')\n",
    "plt.title(\"Exponential Weighted Mean - With Log Transformation\")\n",
    "plt.xlabel('Time (yyyy-mm)')\n",
    "plt.ylabel('log(Oil Production (bbls))')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_log_ewm = ts_log - weighted_avg_exp\n",
    "stationary_test(diff_log_ewm, \"Diff - Log and Exponential Weighted Mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Order differencing - n this technique, we take the difference of the observation at a particular instant with \n",
    "# that at the previous instant. This mostly works well in improving stationarity\n",
    "\n",
    "# Differencing can help stabilize the mean of the time series by removing changes in the level of a time series,\n",
    "# and so eliminating (or reducing) trend and seasonality\n",
    "# https://machinelearningmastery.com/difference-time-series-dataset-python/\n",
    "\n",
    "first_order_diff = ts_log - ts_log.shift()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_order_diff.dropna(inplace=True)\n",
    "plt.figure(figsize=(10, 6))\n",
    "stationary_test(first_order_diff, \"First Order Difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff_active = first_order_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "lag_acf = acf(ts_log_diff_active, nlags=5)\n",
    "lag_pacf = pacf(ts_log_diff_active, nlags=5, method=\"ols\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot ACF:\n",
    "plt.subplot(121)\n",
    "plt.plot(lag_acf, color = 'blue')\n",
    "plt.axhline(y=0, linestyle=\"--\", color=\"gray\")\n",
    "plt.axhline(y=-1.96 / np.sqrt(len(ts_log_diff_active)), linestyle=\"--\", color=\"gray\")\n",
    "plt.axhline(y=1.96 / np.sqrt(len(ts_log_diff_active)), linestyle=\"--\", color=\"gray\")\n",
    "plt.title(\"Autocorrelation Function\")\n",
    "\n",
    "# Plot PACF:\n",
    "plt.subplot(122)\n",
    "plt.plot(lag_pacf, color = 'red')\n",
    "plt.axhline(y=0, linestyle=\"--\", color=\"gray\")\n",
    "plt.axhline(y=-1.96 / np.sqrt(len(ts_log_diff_active)), linestyle=\"--\", color=\"gray\")\n",
    "plt.axhline(y=1.96 / np.sqrt(len(ts_log_diff_active)), linestyle=\"--\", color=\"gray\")\n",
    "plt.title(\"Partial Autocorrelation Function\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-Regressive Model (p=2, d=1, q=0)\n",
    "model_AR = ARIMA(ts_log, order=(2, 1, 0))\n",
    "results_ARIMA_AR = model_AR.fit(disp=-1)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(ts_log_diff_active, color = 'blue')\n",
    "plt.plot(results_ARIMA_AR.fittedvalues, color=\"red\")\n",
    "plt.title(\"RSS: %.3f\" % sum((results_ARIMA_AR.fittedvalues - first_order_diff) ** 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Average Model (p=0, d=1, q=2)\n",
    "model_MA = ARIMA(ts_log, order=(0, 1, 2))\n",
    "results_ARIMA_MA = model_MA.fit(disp=-1)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(ts_log_diff_active, color = 'blue')\n",
    "plt.plot(results_ARIMA_MA.fittedvalues, color=\"red\")\n",
    "plt.title(\"RSS: %.3f\" % sum((results_ARIMA_MA.fittedvalues - first_order_diff) ** 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined ARIMA model (p=2, d=1, q=2)\n",
    "model = ARIMA(ts_log, order=(2, 1, 2))\n",
    "results_ARIMA = model.fit(disp=-1)\n",
    "print(results_ARIMA.summary())\n",
    "plt.plot(ts_log_diff_active, color = 'blue')\n",
    "plt.plot(results_ARIMA.fittedvalues, color=\"red\")\n",
    "plt.title(\"RSS: %.3f\" % sum((results_ARIMA.fittedvalues - first_order_diff) ** 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual and kde plot\n",
    "from pandas import DataFrame\n",
    "plt.figure(figsize=(10, 5))# plot residual errors\n",
    "residuals = DataFrame(results_ARIMA.resid)\n",
    "residuals.plot(legend=None, color = 'blue')\n",
    "plt.title('Residuals - ARIMA History Match', fontweight='bold', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.plot(kind='kde', legend=None, color = 'blue')\n",
    "plt.title('Kernel Density Estimation - Plot', fontweight='bold', fontsize = 20)\n",
    "plt.show()\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast - ARIMA model\n",
    "results_ARIMA.plot_predict(1, 60)\n",
    "plt.title('ARIMA Model Forecast', fontweight='bold', fontsize = 20)\n",
    "plt.xlabel('Time (years)', fontweight='bold', fontsize = 15)\n",
    "plt.ylabel('Production (bbls)', fontweight='bold', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions converted to right units - ARIMA\n",
    "predictions_ARIMA_diff = pd.Series(results_ARIMA.fittedvalues, copy=True)\n",
    "predictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\n",
    "predictions_ARIMA_log = pd.Series(ts_log, index=ts_log.index)\n",
    "predictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum, fill_value=0)\n",
    "predictions_ARIMA = np.exp(predictions_ARIMA_log)\n",
    "print(predictions_ARIMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(timeseries_train, linewidth = 2, color = 'black')\n",
    "plt.plot(predictions_ARIMA, linestyle = \"--\", color = 'green', linewidth = 2)\n",
    "plt.title(\"RMSE: %.3f\" % np.sqrt(sum((predictions_ARIMA - timeseries_train) ** 2) / len(timeseries_train)), fontweight='bold', fontsize = 20)\n",
    "plt.gca().legend((\"Original Decline Curve\", \"ARIMA Model Decline Curve\"))\n",
    "plt.xlabel('Time (yyyy-mm)', fontweight='bold', fontsize = 15)\n",
    "plt.ylabel('Oil Production (bbls)', fontweight='bold', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = results_ARIMA.forecast(steps=12)[0]\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert the differenced forecast results to covert to right units\n",
    "X = timeseries_train.values\n",
    "history = [x for x in X]\n",
    "months_in_year = 12\n",
    "Month = 1\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]\n",
    "\n",
    "for yhat in forecast:\n",
    "    inverted = inverse_difference(history, yhat, months_in_year)\n",
    "    print(Month, inverted)\n",
    "    history.append(inverted)\n",
    "    Month += 1\n",
    "\n",
    "history\n",
    "forecast_12_months = history[-12:] # last 12 forecasted values\n",
    "predictions_ARIMA = predictions_ARIMA.to_numpy()\n",
    "forecast_12_months = np.array(forecast_12_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions_ARIMA)\n",
    "print(forecast_12_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_model_results = np.concatenate((predictions_ARIMA, forecast_12_months))\n",
    "arima_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_train.values # oil rate - train\n",
    "timeseries_test # oil rate - test\n",
    "forecast_12_months # oil rate - forecast\n",
    "\n",
    "ts_np = timeseries_train.to_numpy()\n",
    "ts_forecast = np.array(forecast_12_months)\n",
    "ts_test_np = timeseries_test.to_numpy()\n",
    "\n",
    "actual = np.concatenate([ts_np, ts_test_np])\n",
    "actual = np.delete(actual, -1)\n",
    "actual\n",
    "\n",
    "forecast = np.concatenate([predictions_ARIMA, ts_forecast])\n",
    "forecast = np.delete(forecast, -1)\n",
    "forecast\n",
    "\n",
    "time = pd.date_range(start='6/1/2015', periods= 54, freq='MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "rmse = sqrt(mean_squared_error(actual, forecast))\n",
    "print(\"RMSE - ARIMA Method:\", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
